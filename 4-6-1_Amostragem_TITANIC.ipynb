{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando a base\n",
    "train = pd.read_csv('train_treated.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>71.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  Sex        Age  SibSp  Parch     Fare  \\\n",
       "PassengerId                                                            \n",
       "885                 0       3    0  25.000000      0      0   7.0500   \n",
       "541                 1       1    1  36.000000      0      2  71.0000   \n",
       "79                  1       2    0   0.830000      0      2  29.0000   \n",
       "109                 0       3    0  38.000000      0      0   7.8958   \n",
       "411                 0       3    0  29.699118      0      0   7.8958   \n",
       "\n",
       "             Embarked_C  Embarked_Q  Embarked_S  \n",
       "PassengerId                                      \n",
       "885                   0           0           1  \n",
       "541                   0           0           1  \n",
       "79                    0           0           1  \n",
       "109                   0           0           1  \n",
       "411                   0           0           1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividindo entre treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(train.drop(columns=['Survived']), train['Survived'], test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando dicionario de scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando os melhores modelos pós gridsearch\n",
    "import pickle\n",
    "filename = 'gridsearch_scores'\n",
    "infile = open(filename,'rb')\n",
    "metrics_dict = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Logistic GS', 'SVM GS', 'Decision GS', 'Neural GS'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>predict</th>\n",
       "      <th>classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic GS</td>\n",
       "      <td>0.802691</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>[0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, ...</td>\n",
       "      <td>LogisticRegression(C=0.045227288910538066, cla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM GS</td>\n",
       "      <td>0.784753</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, ...</td>\n",
       "      <td>SVC(C=492.1132712266245, break_ties=False, cac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision GS</td>\n",
       "      <td>0.820628</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.726190</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>[0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, ...</td>\n",
       "      <td>DecisionTreeClassifier(ccp_alpha=0.0, class_we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neural GS</td>\n",
       "      <td>0.820628</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.726190</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>[0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, ...</td>\n",
       "      <td>MLPClassifier(activation='relu', alpha=0.01, b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label  accuracy    recall  precision        F1  \\\n",
       "0  Logistic GS  0.802691  0.777778   0.666667  0.717949   \n",
       "1       SVM GS  0.784753  0.714286   0.714286  0.714286   \n",
       "2  Decision GS  0.820628  0.782051   0.726190  0.753086   \n",
       "3    Neural GS  0.820628  0.782051   0.726190  0.753086   \n",
       "\n",
       "                                             predict  \\\n",
       "0  [0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, ...   \n",
       "1  [0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, ...   \n",
       "2  [0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, ...   \n",
       "3  [0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, ...   \n",
       "\n",
       "                                          classifier  \n",
       "0  LogisticRegression(C=0.045227288910538066, cla...  \n",
       "1  SVC(C=492.1132712266245, break_ties=False, cac...  \n",
       "2  DecisionTreeClassifier(ccp_alpha=0.0, class_we...  \n",
       "3  MLPClassifier(activation='relu', alpha=0.01, b...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(metrics_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dict(name, predict, classifier, dictionary):\n",
    "    dictionary[name] = {\n",
    "        'label': name, \n",
    "        'accuracy': metrics.accuracy_score(predict, y_test), \n",
    "        'recall': metrics.recall_score(predict, y_test), \n",
    "        'precision': metrics.precision_score(predict, y_test), \n",
    "        'F1': metrics.f1_score(predict, y_test),\n",
    "        'predict': predict,\n",
    "        'classifier': classifier\n",
    "    }\n",
    "    return dictionary\n",
    "    \n",
    "def update_score_dict(name, predict, classifier):\n",
    "    update_dict(name, predict, classifier, metrics_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging e boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_num_estimators(classifier, estimator, n_est):\n",
    "    num_estimators = n_est if n_est else [20, 25, 30, 40, 60, 80, 90, 100]\n",
    "    results_dict = {elem: {} for elem in num_estimators}\n",
    "\n",
    "\n",
    "    for i in num_estimators:\n",
    "        classif = classifier(base_estimator=estimator, n_estimators=i, random_state=0)\n",
    "        classif.fit(x_train, y_train)\n",
    "        classif_predict = classif.predict(x_test)\n",
    "        update_dict(i, classif_predict, classif, results_dict)\n",
    "        \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_num_estimators_for_boosting(estimator, n_est=None):\n",
    "    return test_num_estimators(AdaBoostClassifier, estimator, n_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_num_estimators_for_bagging(estimator, n_est=None):\n",
    "    return test_num_estimators(BaggingClassifier, estimator, n_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Instanciando\n",
    "logisticR = metrics_dict['Logistic GS']['classifier']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est_LR = [100, 200, 300, 350, 400, 410, 415, 420, 425, 450, 470, 500]\n",
    "results_dict_LR = test_num_estimators_for_boosting(logisticR, n_est_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordered by F1\n",
    "newlist_LR = sorted(list(results_dict_LR.values()), key=lambda k: k['F1']) \n",
    "pd.DataFrame(newlist_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_logistic_best = results_dict_LR[400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_score_dict('Logistic GS Ada', adaboost_logistic_best['predict'], adaboost_logistic_best['classifier'])\n",
    "pd.DataFrame(metrics_dict.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Máquina de Vetor Suporte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando\n",
    "from sklearn.svm import SVC\n",
    "# Instanciando\n",
    "supportV = metrics_dict['SVM GS']['classifier']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict_SVM = test_num_estimators_for_bagging(supportV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ordered by F1\n",
    "newlist_SVM = sorted(list(results_dict_SVM.values()), key=lambda k: k['F1']) \n",
    "pd.DataFrame(newlist_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est_SVM = [300, 400, 500, 600]\n",
    "results_dict_SVM_high = test_num_estimators_for_bagging(supportV, n_est_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordered by F1\n",
    "newlist_SVM_high = sorted(list(results_dict_SVM_high.values()), key=lambda k: k['F1']) \n",
    "pd.DataFrame(newlist_SVM_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_svm_best = results_dict_SVM[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_score_dict('SVM GS Bagging', bagging_svm_best['predict'], bagging_svm_best['classifier'])\n",
    "pd.DataFrame(metrics_dict.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Instanciando\n",
    "decisionT = metrics_dict['Decision GS']['classifier']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est_DT = [20, 25, 30, 35, 37, 39, 40, 45, 50, 53, 55, 57, 60, 80, 90]\n",
    "results_dict_DT = test_num_estimators_for_boosting(decisionT, n_est_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordered by F1\n",
    "newlist_DT = sorted(list(results_dict_DT.values()), key=lambda k: k['F1']) \n",
    "pd.DataFrame(newlist_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est_DT_high = [200, 300, 500, 600, 680, 700, 800, 815, 820, 825, 850, 900, 1000]\n",
    "results_dict_DT_high = test_num_estimators_for_boosting(decisionT, n_est_DT_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordered by F1\n",
    "newlist_DT_high = sorted(list(results_dict_DT_high.values()), key=lambda k: k['F1']) \n",
    "pd.DataFrame(newlist_DT_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_decisionT_best = results_dict_DT_high[820]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_score_dict('Decision GS Ada', adaboost_decisionT_best['predict'], adaboost_decisionT_best['classifier'])\n",
    "pd.DataFrame(metrics_dict.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neurais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# Instanciando\n",
    "neuralN =  metrics_dict['Neural GS']['classifier']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est_NN = [10, 20, 23, 25, 30, 60, 65, 70, 80, 85, 100]\n",
    "results_dict_NN = test_num_estimators_for_bagging(neuralN, n_est_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ordered by F1\n",
    "newlist_NN = sorted(list(results_dict_NN.values()), key=lambda k: k['F1']) \n",
    "pd.DataFrame(newlist_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est_NN_low = [1, 5, 7, 8, 9, 10, 13, 15]\n",
    "results_dict_NN_low = test_num_estimators_for_bagging(neuralN, n_est_NN_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordered by F1\n",
    "newlist_NN_low = sorted(list(results_dict_NN_low.values()), key=lambda k: k['F1']) \n",
    "pd.DataFrame(newlist_NN_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_neuralN_best = results_dict_NN[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_score_dict('Neural GS Bagging', bagging_neuralN_best['predict'], bagging_neuralN_best['classifier'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metrics_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordered by F1\n",
    "newlist = sorted(list(metrics_dict.values()), key=lambda k: k['F1']) \n",
    "f1_ordered = pd.DataFrame(newlist)\n",
    "f1_ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for keys in [['Logistic GS', 'Logistic GS Ada'], ['SVM GS', 'SVM GS Bagging'], ['Decision GS', 'Decision GS Ada'], ['Neural GS', 'Neural GS Bagging']]:\n",
    "    selected_methods_dict = {x:metrics_dict[x] for x in keys}\n",
    "    \n",
    "    print(pd.DataFrame(selected_methods_dict).drop(['label', 'predict', 'classifier', 'recall', 'precision']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metrics_dict).drop(['label', 'recall', 'precision', 'predict', 'classifier']).plot(kind='bar', figsize=(9,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvando resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['Logistic GS', 'SVM GS Bagging', 'Decision GS', 'Neural GS']\n",
    "selected_methods_dict = {x:metrics_dict[x] for x in keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvando \n",
    "import pickle\n",
    "filename = 'amostragem_scores'\n",
    "outfile = open(filename, 'wb')\n",
    "pickle.dump(selected_methods_dict, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
